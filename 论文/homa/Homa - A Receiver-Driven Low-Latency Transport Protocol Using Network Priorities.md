[原文：Homa: A Receiver-Driven Low-Latency Transport Protocol Using Network Priorities](https://people.csail.mit.edu/alizadeh/papers/homa-sigcomm18.pdf)

# 摘要

Homa 是一种用于数据中心网络的新型传输协议。它提供了极低的延迟，尤其适用于包含大量极短消息的工作负载，并且它还支持大消息和高网络利用率。Homa 使用网络内优先级队列来确保短消息的低延迟；优先级分配由每个接收方动态管理，并与接收方驱动的流量控制机制相结合。Homa 还使用对接收方下行链路的受控超量使用，以确保在高负载下的高效带宽利用率。我们对 Homa 的实现，在运行于 80%负载的 10 Gbps 网络上，对于短消息实现了小于 15 微秒的 99 百分位往返时间。这些延迟几乎比已发布的最佳实现测量值低 100 倍。在模拟中，对于几乎所有消息大小和工作负载，Homa 的延迟大致与 pFabric 相等，并且明显优于 pHost、PIAS 和 NDP。Homa 还能够比 pFabric、pHost 或 PIAS 维持更高的网络负载。

# 导论

在过去十年中，数据中心计算的兴起为网络传输协议创造了新的运行条件。现代数据中心网络硬件为极低延迟通信提供了可能性。现在，短消息的往返时间有可能达到5微秒或更短，并且已经出现了各种可以利用这种低延迟的应用程序[20, 24, 26]。此外，许多数据中心应用使用以极短消息（几百字节或更少）为主的请求 - 响应协议。现有的传输协议不适合这些条件，因此它们为短消息提供的延迟远远高于硬件潜力，特别是在高网络负载下。这表明当前的传输协议在应对数据中心新环境时存在不足，无法充分发挥硬件优势，进而引出了Homa协议设计的必要性，它旨在解决这些问题，以满足数据中心对短消息低延迟传输的需求。
近年来，人们提出了许多改进传输协议的方案，包括对TCP的改进[2, 3, 31]以及各种新协议[4, 6, 14, 15, 17, 25, 32]。然而，这些设计都没有考虑到如今的小消息尺寸；它们基于重尾工作负载，在这种负载下，100千字节的消息被视为“小”消息，并且延迟通常以毫秒为单位测量，而不是微秒。因此，在高网络负载下，仍然没有为短消息提供接近硬件延迟的实用解决方案。例如，我们不知道有任何现有实现能够在高网络负载下（在硬件潜力的20倍以内）实现100微秒或更低的尾延迟。
Homa是一种为低延迟数据中心环境中的小消息而设计的新型传输协议。我们对Homa的实现，在10 Gbps链路速度且网络负载为80%的情况下，对于小消息实现了小于15微秒的99百分位往返延迟，即使在存在竞争的大消息时也能做到这一点。在广泛的消息大小和工作负载范围内，Homa在80%网络负载下实现的99百分位延迟是空载网络上最小可能延迟的2 - 3.5倍以内。尽管Homa倾向于小消息，但与基于公平共享的类似TCP的方法相比，它也提高了大消息的性能。
Homa使用了两项创新来实现其高性能。首先是它积极利用现代网络交换机提供的优先级队列。为了充分利用有限数量的优先级队列，Homa在接收端动态分配优先级，并将优先级与类似pHost [13]和NDP [15]的接收端驱动的流控制机制相结合。与之前的接收端驱动方法相比，Homa的优先级机制将尾延迟提高了2 - 16倍。与PIAS [6]等发送端驱动的优先级机制相比，Homa能更好地近似SRPT（最短剩余处理时间优先）；这使得尾延迟比PIAS降低了0 - 3倍。
Homa的第二个贡献是其使用了受控的过度承诺机制，即接收方允许几个发送方同时传输。通过这种方式稍微过度承诺接收方下行链路，使得Homa能够高效利用网络带宽：Homa能够维持比pFabric [4]、PIAS、pHost和NDP高2 - 33%的网络负载。Homa限制了过度承诺，并将其与优先级机制相结合，以防止短消息排队。
Homa还有其他一些有助于其高性能的不寻常特性。它采用基于消息的架构而非流传输方式，这消除了发送方的队头阻塞问题，与TCP等流传输相比，尾延迟降低了100倍。Homa是无连接的，这减少了大规模应用中的连接状态。它没有显式确认，减少了小消息的开销，并实现了至少一次语义而非至多一次语义。

# 动机和关键思想

Homa 的主要目标是在高网络负载下，利用当前网络硬件为短消息提供尽可能低的延迟。我们关注尾消息延迟（99 百分位），因为它是数据中心应用中最重要的指标 [2, 33]。近年来，大量工作都集中在低延迟数据中心传输上。然而，正如我们的结果将显示的，现有设计在高网络负载下对于尾延迟并非最优，特别是在原始硬件延迟为个位数微秒的网络中 [9, 21, 28, 34]。在本节中，我们将讨论此类网络中出现的挑战，并推导出 Homa 的关键设计特征。

## 动机：短延迟的短消息

最先进的直通式交换机的延迟最多只有几百纳秒[30]。低延迟网络接口卡和软件栈（例如，DPDK [9]）在过去几年中也变得很常见。这些进步使得在没有排队的情况下，即使在包含数千台服务器的大型网络（例如，三级胖树网络）中，实现几微秒的单向延迟也成为了可能。
与此同时，许多数据中心应用依赖于带有几百字节或更少微小消息的请求 - 响应协议。在典型的远程过程调用（RPC）使用案例中，几乎总是请求或响应中的一个是微小的，因为数据通常仅在一个方向上流动。数据本身通常也很短。图 1 展示了我们用于设计和评估 Homa 的一系列工作负载，其中大部分是从谷歌和脸书的数据中心应用中测量得到的。在其中三个工作负载中，超过 85%的消息小于 1000 字节。在最极端的情况（W1）下，以字节衡量，超过 70%的所有网络流量都在小于 1000 字节的消息中。
据我们所知，几乎所有先前的工作都集中在具有非常大消息的工作负载上。例如，在用于评估 DCTCP [2]和 pFabric [4]的 Web 搜索工作负载中（图 1 中的 W5），长度超过 1 兆字节的消息占传输字节的 95%，而任何小于 100 千字节的消息都被视为“短”消息。大多数后续工作都使用了相同的工作负载。为了获得这些工作负载，消息大小是根据 TCP 连接在超过阈值（例如，50 毫秒）的不活动时间从数据包捕获中估计出来的。不幸的是，这种方法高估了消息大小，因为一个 TCP 连接可以包含许多紧密排列的消息。在图 1 中，工作负载 W1 - W3 是根据应用层消息明确测量的，它们显示出比从数据包捕获中提取的工作负载 W4 和 W5 小得多的大小。
不幸的是，现有的数据中心传输设计无法在高网络负载下为微小消息实现尽可能低的延迟。我们将在下一节探索设计空间，例如，考虑那些不利用网络内优先级的设计（如 HULL [3]、PDQ [17]、NDP [15]）。这些设计试图限制队列堆积，但它们都无法完全消除排队现象。最先进的方法 NDP [15]将队列严格限制为 8 个数据包，在 10 Gbps 的情况下相当于大约 10 微秒的延迟。虽然这种排队延迟在具有中等延迟（例如，往返时间大于 50 微秒）的网络或中等大小消息（例如，100 千字节）的情况下影响可以忽略不计，但在往返时间为 5 微秒的网络中，它会使 200 字节消息的完成时间增加 5 倍。

## 设计空间

我们现在对低延迟数据中心传输协议的设计空间进行探讨。我们推导出 Homa 的四个关键设计原则：（i）盲目传输短消息，（ii）使用网络内优先级，（iii）在接收端动态分配优先级并结合接收端驱动的速率控制，以及（iv）对接收方下行链路进行受控的过度承诺。虽然过去的一些设计使用了前两个技术，但我们表明，将这四个技术结合起来对于在高网络负载下实现最低延迟至关重要。
我们关注消息延迟（而非数据包延迟），因为它反映了应用程序的性能。消息是从单个发送方传输到单个接收方的任意长度的字节块。发送方在将消息的第一个字节提交给传输层时必须指定消息的大小，并且接收方在收到整个消息之前无法对其进行处理。消息大小的信息特别有价值，因为它允许传输层优先处理较短的消息。
在低延迟交付短消息的关键挑战是消除排队延迟。与先前的工作类似，我们假设网络核心的带宽足以容纳所提供的负载，并且网络支持高效的负载均衡 [1, 10, 16]，以便数据包在可用路径上均匀分布（在我们的设计中，我们假设采用简单的随机逐包分发）。因此，排队主要发生在从机架顶部交换机（TOR）到机器的下行链路中。当多个发送方同时向同一接收方传输时，就会出现这种情况。最坏的情况是集中式传输（Incast），即一个应用程序同时向多个服务器发起 RPC 请求，并且所有响应同时到达。
没有时间对每个数据包进行调度。一种理想的方案可能会尝试像 Fastpass [25] 那样在中央仲裁器处对每个数据包进行调度。这样的仲裁器可以考虑所有消息，并做出关于从每个发送方传输哪个数据包以及何时传输的全局调度决策。理论上，仲裁器可以完全避免网络中的排队。然而，这种方法会使短消息的延迟增加两倍：一个微小的单数据包消息如果需要等待调度决策，至少需要 1.5 个往返时间，而如果立即传输则可以在 0.5 个往返时间内完成。基于接收方的调度机制，如 ExpressPass [8]，也会遭受同样的惩罚。
为了实现尽可能低的延迟，短消息必须盲目传输，而不考虑潜在的拥塞。一般来说，发送方必须盲目传输足够的数据来覆盖到接收方的往返时间（包括两端的软件开销）；在此期间，接收方可以返回明确的调度信息以控制未来的传输，而不会引入额外的延迟。我们将此数据量称为 RTT 字节；在我们针对 10 Gbps 网络的 Homa 实现中，它大约为 10 KB。
缓冲是一种必要之恶。盲目传输意味着当多个发送方向同一接收方传输时可能会发生缓冲。没有协议可以在不产生一些缓冲的情况下实现最小延迟。但具有讽刺意味的是，当缓冲发生时，它会增加延迟。许多先前的设计试图减少缓冲，例如通过精心设计的速率控制方案 [2, 21, 34]、预留带宽余量 [3]，甚至将缓冲区大小严格限制为一个小值 [15]。然而，这些方法都无法完全消除缓冲带来的延迟惩罚。
网络内优先级是必须的。鉴于缓冲的不可避免性，实现最低延迟的唯一方法是使用网络内优先级。现代交换机的每个输出端口支持少量的优先级级别（通常为 8 个），每个优先级有一个队列。每个传入数据包指示该数据包应使用哪个队列，并且输出端口会先服务高优先级队列，然后再服务低优先级队列。低延迟的关键是分配数据包优先级，以便短消息绕过为长消息排队的数据包。
这一观察结果并不新鲜；从 pFabric [4] 开始，一些方案已经表明基于交换机的优先级可以用于改善消息延迟 [6, 7, 13, 14]。这些方案使用优先级来实现各种基于消息大小的调度策略。其中最常见的策略是 SRPT（最短剩余处理时间优先），它优先处理来自剩余字节数最少的消息的数据包。SRPT 提供了接近最优的平均消息延迟，并且如先前工作所示 [4, 17]，它也为短消息提供了非常好的尾延迟。Homa 实现了 SRPT 的近似（尽管该设计也可以支持其他策略）。
不幸的是，在实践中，没有现有方案能够在高网络负载下实现 SRPT 的接近最优延迟。pFabric 准确地近似了 SRPT，但它需要太多的优先级级别，无法在当今的交换机上实现。PIAS [6] 在有限数量的优先级下工作，但它在发送方分配优先级，这限制了其近似 SRPT 的能力（见下文）。此外，它不使用消息大小，因此使用 “多级队列” 调度策略。结果，PIAS 对于短消息和长消息都具有较高的尾延迟。QJUMP [14] 要求根据每个应用程序手动分配优先级，这太不灵活，无法产生最优延迟。
充分利用有限的优先级需要接收方控制。为了在只有少量优先级级别的情况下产生对 SRPT 的最佳近似，优先级应由接收方确定。除了盲目传输外，接收方知道在其从 TOR 交换机的下行链路上争夺带宽的消息的确切集合。因此，接收方可以最好地决定为每个传入数据包使用哪个优先级。此外，接收方可以通过将优先级与数据包调度机制集成来增强优先级的有效性。
pHost [13] 是与 Homa 最接近的先前方案，是使用接收方驱动方法近似 SRPT 的一个例子。其主要机制是数据包调度：发送方盲目传输每个消息的前 RTT 字节，但此后的数据包仅在收到接收方的明确授权后才传输。接收方调度授权以实现 SRPT，同时控制数据包的流入以匹配下行链路速度。
然而，pHost 对优先级的利用有限：它静态地为所有盲目传输分配一个高优先级，为所有调度数据包分配一个较低优先级。这在两个方面影响了其近似 SRPT 的能力。首先，它将所有盲目传输捆绑到一个优先级中。虽然对于大多数字节来自大消息的工作负载（图 1 中的 W4 - W5）这是合理的，但对于大部分字节盲目传输的工作负载（W1 - W3）则存在问题。其次，对于长度超过 RTT 字节的消息，pHost 无法立即为较短的消息抢占较大的消息。同样，问题的根源在于 pHost 将所有此类消息捆绑到一个优先级中，这导致了排队延迟。我们将在 §3.4 中表明，这会产生抢占延迟，这会损害延迟，特别是对于持续几个往返时间的中等大小消息。
接收方必须动态分配优先级。Homa 通过在接收方动态分配多个优先级来解决 pHost 的局限性。每个接收方使用两种机制为其自己的下行链路分配优先级。对于长度大于 RTT 字节的消息，接收方根据确切的入站消息集动态地向其发送方传达每个数据包的优先级。这几乎消除了所有的抢占延迟。对于盲目发送的短消息，发送方无法知道接收方的其他入站消息。即便如此，接收方可以根据其最近的工作负载提前向发送方提供指导。我们的实验表明，与 pHost 或 PIAS 等静态优先级分配方案相比，动态优先级管理大大降低了尾延迟。
接收方必须以受控的方式过度承诺其下行链路。通过接收方的授权来调度数据包传输可以减少缓冲区占用，但它引入了一个新的挑战：接收方可能向一个发送方发送授权，但该发送方未能及时向其传输。例如，当一个发送方有多个接收方的消息时，如果多个接收方决定向其发送授权，发送方无法以全速向所有这些接收方传输数据包。这在接收方下行链路浪费了带宽，并可能在高网络负载下严重损害性能。例如，我们发现，尽管使用了超时机制来减轻无响应发送方的影响，但 pHost 能够支持的最大负载在 58% 到 73% 之间，具体取决于工作负载（§5.2）。NDP [15] 也调度传入数据包以避免缓冲区堆积，并且也遭受类似的问题。
为应对这一挑战，Homa的接收方有意通过同时向少量发送方授予权限来过度承诺其下行链路；这会导致在接收方的TOR（机架顶部交换机）处形成可控的数据包排队，但对于在高负载下实现高网络利用率和最佳消息延迟至关重要（§3.5）。
发送方也需要 SRPT。在发送方和接收方都可能出现队列堆积，这可能导致短消息的长时间延迟。例如，大多数现有协议实现字节流，并且应用程序通常为每个目的地使用单个流。然而，这可能导致队头阻塞，即对于给定目的地的短消息在字节流中排在同一目的地的长消息后面。§5.1 将表明，这会使短消息的尾延迟增加 100 倍。即使消息在不同的流上传输，NIC 中的先进先出数据包队列也可能导致短消息的高尾延迟。为了实现低尾延迟，发送方必须确保短传出消息不会被长消息延迟。
综上所述，图2展示了Homa协议的概述。Homa将消息分为两部分：初始的未调度部分，随后是调度部分。发送方立即传输未调度数据包（RTT字节的数据），但在接收方指示之前不会传输任何调度数据包。未调度数据包的到达使接收方知晓消息；接收方然后通过为每个调度数据包发送一个授权数据包来请求传输调度数据包。Homa的接收方动态为调度数据包设置优先级，并定期通知发送方一组用于为未调度数据包设置优先级的阈值。最后，接收方实施受控的过度承诺，以便在存在无响应发送方的情况下维持高利用率。最终效果是使用少量优先级队列精确近似SRPT调度策略。我们将展示这在广泛的工作负载和流量条件下都能产生出色的性能。

![](Pasted%20image%2020241120212432.png)
图2：Homa协议概述。发送方1正在传输消息m1的调度数据包，而发送方2正在传输消息m2的未调度数据包。

# Homa 的设计

本节详细描述了Homa协议。除了阐述Homa如何实现上一节所提出的关键思路外，本节还讨论了该协议的其他几个方面，这些方面对性能的影响并非至关重要，但却为数据中心的远程过程调用（RPC）提供了一个完整且实用的基础架构。Homa包含几个不同寻常的特性：它是由接收方驱动的；它是面向消息的，而非面向流的；它是无连接的；它不使用显式确认；并且它实现的是至少一次语义，而非更为传统的至多一次语义。Homa使用四种数据包类型，如图3所示进行了概括。

| Name   | Description                                                                                                                                                 |
| ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| DATA   | 由发送方发送至接收方。包含消息内由偏移量和长度所界定的一段字节内容，同时也标明消息的总长度。                                                                |
| GRANT  | 由接收方发送至发送方。表示发送方现在可以传输消息中直至给定偏移量的所有字节，并指定要使用的优先级。                                                          |
| RESEND | 由接收方发送至发送方。表示发送方应重新传输消息内给定范围的字节。                                                                                            |
| BUSY   | 由发送方发送至接收方。表示对重发（RESEND）请求的响应将会延迟（发送方正忙于传输更高优先级的消息，或者一个远程过程调用（RPC）操作仍在执行中）；用于防止超时。 |

图 3：Homa 所使用的数据包类型。除数据（DATA）数据包外，所有其他类型的数据包均以最高优先级发送；数据数据包的优先级由接收方按照§3.4 所述进行指定。

## 远程过程调用（RPCs），而非连接

Homa 是无连接的。它实现了远程过程调用（RPC）的基本数据传输功能，每个 RPC 都包含一条从客户端发往服务器的请求消息以及与之对应的响应消息。每个 RPC 都由客户端生成的一个全球唯一的 RPC 标识（RPCid）来标识。该 RPCid 会包含在与该 RPC 相关的所有数据包中。客户端在同一时间可以向任意数量的服务器发起任意数量的未完成 RPC；发往同一服务器的并发 RPC 可能会以任意顺序完成。
消息的独立传输对于低尾延迟至关重要。TCP 所使用的流传输方式会导致队头阻塞，即对于同一目的地，短消息会排在长消息后面排队。§5.1 将表明这会使短消息的尾延迟增加 100 倍。许多近期的提案，如 DCTCP、pFabric 和 PIAS，假设每个源 - 目标对之间存在数十个连接，以便每个消息都有一个专用连接。然而，这种方法会导致连接状态的爆炸式增长。对于大规模应用而言，即使每个应用 - 服务器对仅有一个连接也是有问题的（[23]§3.1，[11]§3.1），所以使用多个连接可能并不现实。
在客户端向服务器发起远程过程调用（RPC）之前，无需设置阶段或建立连接，而且一旦客户端收到结果，客户端和服务器都不会保留任何关于该 RPC 的状态信息。在数据中心应用中，服务器可能会有大量的客户端；例如，谷歌数据中心的服务器通常会有数以十万计的开放连接[12]。Homa 的无连接方式意味着服务器上所保留的状态是由活动的 RPC 数量决定的，而不是由客户端的总数决定。
Homa 要求对每个远程过程调用（RPC）请求都做出响应，因为这在数据中心应用中是常见的情况，而且这样可以让响应起到对请求的确认作用。这减少了所需的数据包数量（在最简单的情况下，只有一个请求数据包和一个单独的响应数据包）。单向消息可以通过让服务器应用在收到请求后立即返回一个空响应来模拟。
Homa 处理请求消息和响应消息的方式几乎相同，所以在下面的大部分讨论中，我们不会对请求和响应加以区分。
虽然我们是为了新型数据中心应用（在这类应用中远程过程调用（RPC）很适用）而设计的 Homa，但我们认为，通过在 Homa 之上实现类似套接字的字节流接口，传统应用也能够得到支持。我们把这部分内容留作未来的研究工作。

## 发送者的基本行为

当消息到达发送方的传输模块时，Homa将其分为两部分：初始的未调度部分（前RTT字节），随后是调度部分。发送方立即使用一个或多个数据（DATA）数据包传输未调度字节，直到接收方使用授权（GRANT）数据包明确请求，才传输调度字节。每个DATA数据包都有一个优先级，该优先级由接收方按§3.4所述确定。
发送方对传出数据包实现最短剩余处理时间优先（SRPT）策略：若多个消息的DATA数据包同时准备好传输，先发送剩余字节数最少的消息的数据包。发送方在调度数据包传输时不考虑DATA数据包中的优先级（其优先级用于到接收方的最终下行链路），授权和重发等控制数据包始终优先于DATA数据包。

## 流量控制

Homa中的流量控制在接收方通过逐个数据包地调度传入数据包来实现，类似pHost和NDP。在大多数情况下，每当一个数据（DATA）数据包到达接收方时，接收方会向发送方发送一个授权（GRANT）数据包。该授权邀请发送方传输消息中直到给定偏移量的所有字节，且偏移量的选择确保消息中总有已授权但尚未接收的RTT字节的数据。假设授权能及时返回给发送方且无其他消息竞争，消息可全速无延迟地从头到尾传输。
若多个消息同时到达接收方，它们的DATA数据包将根据优先级交错。若一个消息的DATA数据包延迟，其GRANT也会延迟，所以一个消息已授权但未接收的数据不会超过RTT字节，这意味着每个传入消息在接收方的TOR（机架顶部交换机）中最多占用RTT字节的缓冲区空间。
如果有多个传入消息，接收方可能会停止向部分消息发送授权，这是§3.5中描述的过度承诺限制的一部分。一旦为消息的最后字节发送了授权，该消息的数据数据包可能会导致向之前授权已停止的其他消息发送授权。
消息的数据数据包可以以任何顺序到达，接收方使用每个数据包中的偏移量对它们进行整理。这使得Homa能够使用逐包多路径路由来最小化网络核心中的拥塞。

## 数据包优先级

Homa最具创新性的特点，也是其性能的关键所在，是它对优先级的运用。每个接收方会为其所有传入的数据（DATA）数据包确定优先级，以便近似实现最短剩余处理时间优先（SRPT）策略。它针对未调度数据包和调度数据包采用了不同的机制。对于未调度数据包，接收方会预先分配优先级。它利用近期的流量模式来选择优先级分配方式，并通过搭载在其他数据包上的方式将该信息传播给发送方。每个发送方会保留每个接收方最新的分配信息（每个接收方只需几十字节），并在传输未调度数据包时使用这些信息。如果接收方的传入流量发生变化，它会在下次与每个发送方通信时传播新的优先级分配信息。
Homa为未调度数据包分配优先级，使得每个优先级级别所处理的字节数大致相同。每个接收方会记录其传入消息大小的统计数据，并利用消息大小分布来计算优先级级别，如图4所示。接收方首先计算出所有传入字节中未调度字节所占的比例（在图4中约为80%）。它将可用优先级中的这部分比例（最高的那些）分配给未调度数据包，并将剩余的（较低的）优先级级别预留给调度数据包。然后，接收方在未调度优先级之间确定划分界限，以便每个优先级级别处理相同数量的未调度字节，并且较短的消息使用较高的优先级。
对于已调度数据包，接收方会在每个授权（GRANT）数据包中指定一个优先级，发送方则将该优先级用于已获授权的字节。这使得接收方能够根据所接收的精确消息集动态调整优先级分配；相较于PIAS等由发送方基于历史趋势设置优先级的方法，这种方式能更好地近似实现最短剩余处理时间优先（SRPT）策略。接收方为每条消息使用不同的优先级级别，未获授权字节数较少的消息会被赋予更高的优先级。如果传入的消息数量多于优先级级别数量，那么正如§3.5所述，只有最高优先级的消息会获得授权。如果消息数量少于已调度的优先级级别数量，那么Homa会使用可用优先级中的最低级别；这样就为新的更高优先级消息留出了更高的优先级级别。如果Homa总是使用最高的已调度优先级，就会产生抢占延迟：当一条新的更高优先级消息到达时，由于之前高优先级消息的缓冲数据包，其已调度数据包将会延迟1个往返时间（RTT）（见图5）。使用最低的已调度优先级可以消除抢占延迟，除非所有已调度优先级都在使用。

## Overcommitment

Homa的一个重要设计决策是，接收方在任何给定时间应该允许接收多少条传入消息。接收方可以通过暂不发送授权来停止某条消息的传输；一旦之前已授权的所有数据都到达，在接收方再次开始发送授权之前，发送方不会再为该消息传输任何数据。我们使用“活动”一词来描述接收方愿意为之发送授权的消息；其他消息则为“非活动”消息。
一种可能的做法是在任何时候都让所有传入的消息保持活动状态。这是TCP以及大多数其他现有协议所采用的做法。然而，这种做法会导致缓冲区占用率过高以及消息之间的轮询调度，这两点都会导致高尾延迟。
在我们最初设计Homa时，每个接收方一次只允许有一条活动消息，就像pHost那样。如果一个接收方有多个部分接收的传入消息，它只会向其中优先级最高的消息发送授权；一旦它已授权完最高优先级消息的所有字节，就会开始向次高优先级的消息进行授权，依此类推。采用这种方法的理由是为了将缓冲区占用率降至最低，并实现运行至完成的调度方式，而非轮询调度。
我们的模拟结果显示，在高负载情况下，只允许有一条活动消息会导致网络利用率低下。例如，对于图1中的工作负载W4，无论提供的负载如何，Homa能够使用的网络带宽都不超过约63%。网络未得到充分利用是因为发送方并非总是能立即对授权做出响应，这导致了下行链路带宽被浪费。图6说明了这种情况是如何发生的。
接收方无法知晓某个特定的发送方是否会对授权做出响应，所以要想让下行链路得到充分利用，唯一的办法就是过度承诺：接收方必须一次向不止一个发送方授予权限，即便其下行链路一次只能支持其中一项传输。采用这种方法，如果一个发送方没有响应，那么下行链路就可以供其他某个发送方使用。如果许多发送方同时做出响应，优先级机制会确保最短的消息首先被送达；来自其他消息的数据包将在机架顶部交换机（TOR）中进行缓冲。
接收方无法知晓某个特定的发送方是否会对授权做出响应，所以要想让下行链路得到充分利用，唯一的办法就是过度承诺：接收方必须一次向不止一个发送方授予权限，即便其下行链路一次只能支持其中一项传输。采用这种方法，如果一个发送方没有响应，那么下行链路就可以供其他某个发送方使用。如果许多发送方同时做出响应，优先级机制会确保最短的消息首先被送达；来自其他消息的数据包将在机架顶部交换机（TOR）中进行缓冲。
我们使用“过度承诺程度”这一术语来指代在给定接收方上一次可能处于活动状态的消息的最大数量。如果可用消息数量超过这个最大值，那么只有优先级最高的消息处于活动状态。更高的过度承诺程度会降低带宽被浪费的可能性，但它会消耗机架顶部交换机（TOR）中更多的缓冲空间（每个活动消息最多可达往返时间（RTT）字节），并且可能导致消息之间更多的轮询调度，这会增加平均完成时间。
Homa目前将过度承诺程度设置为已调度优先级级别的数量：接收方对于每个可用的优先级级别最多会向一条消息授予权限。这种方法在我们的模拟中实现了较高的网络利用率，但也存在其他可行的方法。例如，接收方可能会使用一个固定的过度承诺程度，与可用的优先级级别无关（如有必要，几条消息可以共享最低优先级级别）；或者，它可能会根据发送方的响应率动态调整过度承诺程度。我们将对这些替代方案的探索留作未来的研究工作。
需要进行过度承诺这一点再次说明了为什么在传输协议中完全消除缓冲是不切实际的。Homa 引入了恰到好处的缓冲以确保良好的链路利用率；然后它利用优先级来确保缓冲不会影响延迟。

## Incast

Homa利用了这样一个事实来解决扇入（incast）问题：扇入问题通常是自找的，即当一个节点向其他节点发出许多并发的远程过程调用（RPC），且所有这些调用的结果同时返回时就会出现该问题。Homa通过统计每个节点未完成的RPC数量来检测即将发生的扇入情况。一旦这个数量超过阈值，新的RPC就会被标记上一个特殊标记，这会导致服务器在响应消息中对未调度字节使用一个更低的限制（几百字节）。小的响应仍能快速通过，但较大的响应将由接收方进行调度；过度承诺机制会限制缓冲区的使用。通过这种方法，一个规模达到1000倍的扇入情况在机架顶部交换机（TOR）中最多只会消耗几十万字节的缓冲区空间。
扇入（incast）问题也可能以不可预测的方式出现；例如，几台机器可能会同时决定向一台服务器发出请求。然而，这么多请求不太可能同步得足够紧密从而引发扇入问题。如果真的出现这种情况，Homa对缓冲区空间的高效利用仍然使其能够支持数百个请求同时到达而不丢失数据包（见第5.1节）。
扇入（incast）问题在很大程度上是当前数据中心高延迟所导致的结果。如果每个请求都会引发一次耗时 10 毫秒的磁盘 I/O 操作，那么在第一个响应到达之前，客户端就能够发出 1000 个或更多的请求，从而导致大规模的扇入问题。在未来的低延迟环境中，扇入问题将不再那么严重，因为在发出大量请求之前，请求就会完成。例如，在 RAMCloud 主存存储系统 [24] 中，读取请求的端到端往返时间约为 5 微秒。在进行多读取请求时，客户端为不同服务器发出每个请求需要 1 至 2 微秒；当它发出 3 至 4 个远程过程调用（RPC）时，第一批请求的响应就已经开始到达了。因此，未完成的请求很少会超过几个。

## 丢包

我们预计在 Homa 中数据包丢失的情况会很少见。数据包丢失有两个原因：网络中的数据损坏以及缓冲区溢出。在现代数据中心网络中，数据损坏的情况极为罕见，而且 Homa 充分减少了缓冲区的使用，使得缓冲区溢出的情况也极为少见。由于数据包几乎从不丢失，所以 Homa 针对数据包未丢失的常见情况对丢失数据包的处理进行了优化以提高效率，并且在数据包丢失时采取了较为简单的处理方式。
在TCP协议中，发送方负责检测丢失的数据包。这种方式需要确认数据包，这给协议增加了开销（最简单的远程过程调用（RPC）就需要两个数据包和两个确认信息）。在Homa协议中，丢失的数据包由接收方来检测；因此，Homa协议不使用任何明确的确认信息。这使得简单的RPC所需的数据包数量减少了一半。接收方使用一种基于超时的简单机制来检测丢失的数据包。如果在很长一段时间（几毫秒）内，某条消息没有额外的数据包到达，接收方就会发送一个重发（RESEND）数据包，指明缺失字节的首个范围；然后发送方就会重新传输那些字节。
如果一个远程过程调用（RPC）请求的所有初始数据包都丢失了，服务器将不会知晓该消息，因此它不会发出重发（RESEND）请求。然而，客户端会对响应消息进行超时处理，并会针对该响应发送一个重发请求（即便请求尚未完全传输，它也会这样做）。当服务器收到一个针对带有未知 RPC 标识的响应的重发请求时，它会假定请求消息肯定已经丢失，并会针对请求的前往返时间（RTT）字节发送一个重发请求。
如果客户端对重发（RESEND）请求未收到任何响应（由于服务器或网络故障），它会多次重试重发请求，最终中止该远程过程调用（RPC），并向更高级别的软件返回一个错误信息。

## 至少一次语义

RPC协议传统上实现的是至多一次语义，即在正常情况下每个RPC恰好执行一次；在发生错误时，一个RPC可能执行一次或者根本不执行。Homa允许RPC执行多次：在正常情况下，一个RPC会执行一次或多次；在发生错误后，它可能已经执行了任意次数（包括零次）。Homa在两种情况下会重新执行RPC。首先，Homa不保留连接状态，所以如果在服务器已经处理了原始请求并丢弃其状态后，一个重复的请求数据包到达，Homa将重新执行该操作。其次，服务器没有收到响应已被接收的确认信息，所以没有明显的安全时间来丢弃响应。由于数据包丢失的情况很少见，服务器采取最简单的方法，一旦发送了最后一个响应数据包，就立即丢弃RPC的所有状态。如果一个响应数据包丢失，服务器可能在删除RPC状态后收到重发（RESEND）请求。在这种情况下，它将表现得好像从未收到过请求一样，并为该请求发出重发请求；这将导致RPC的重新执行。
Homa允许重新执行操作，因为这简化了实现过程，并且允许服务器丢弃不活跃客户端的所有状态（至多一次语义要求服务器为每个客户端保留足够的状态以检测重复请求）。此外，对于大多数数据中心应用程序来说，传输层的重复数据抑制是不够的。例如，考虑一个复制存储系统：如果某个副本在执行客户端请求时崩溃，客户端将会向另一个不同的副本重试该请求。然而，有可能原始副本在崩溃之前就已经完成了操作。因此，即使传输层实现了至多一次语义，崩溃恢复机制也可能导致请求的重新执行。必须在传输层之上的某个层级对重复数据进行过滤。
Homa 假定更高级别的软件要么能够容忍远程过程调用（RPC）的冗余执行，要么能将其过滤掉。这种过滤可以通过特定于应用程序的机制来完成，也可以借助诸如 RIFL [19]等通用机制来实现。例如，可以在 Homa 之上构建一个非常薄的类似 TCP 的流机制层，该层能够丢弃重复数据并保持数据顺序。

# 实现

我们将 Homa 作为一种新的传输协议在 RAMCloud 主存存储系统[24]中进行了实现。RAMCloud 支持多种使用不同网络技术的传输协议，并且它拥有一个经过高度优化的软件栈：在大多数传输协议中，发送或接收一个远程过程调用（RPC）的软件总开销为 1 至 2 微秒。Homa 传输协议基于 DPDK[9]，这使得它能够绕过内核并直接与网卡进行通信；Homa 通过轮询而非中断的方式来检测传入的数据包。Homa 的实现总共包含 3660 行 C++代码，其中大约一半是注释。
Homa 在 RAMCloud 中的实现包含了本文所描述的所有功能，除了它尚未实时测量传入消息的长度（其优先级是根据对基准工作负载的了解预先计算出来的）。
Homa 传输协议包含一个之前未描述的额外机制，该机制限制了网卡传输队列中的缓冲区积累。为了让发送方精确地实现最短剩余处理时间（SRPT），它必须使网卡中的传输队列保持较短，这样高优先级数据包就不必等待先前排队的低优先级数据包（如第 3.2 节所述，发送方对于外发数据包的优先级不一定与数据包中存储的优先级相对应）。为此，Homa 会持续估算网卡中未传输字节的总数，并且只有当未传输字节数（包括新数据包）为两个完整大小数据包或更少时，才会将数据包交给网卡。这使得发送方在新消息到达时能够重新排列外发数据包的顺序。

# 评估

我们通过测量 RAMCloud 中的实现以及运行模拟来评估 Homa。我们的目标是回答以下问题：

- Homa 在高网络负载和存在长消息的情况下，是否能为短消息提供低延迟？
- Homa 对网络带宽的利用效率如何？
- Homa 与现有的最先进方法相比如何？
- Homa 的新特性对其性能有多重要？

## 测量实现

我们使用图 7 所描述的 CloudLab 集群来测量 Homa 在 RAMCloud 中的实现性能。该集群包含 16 个节点，这些节点通过 10 吉比特每秒的以太网连接到一台交换机上；其中 8 个节点用作客户端，另外 8 个用作服务器。每个客户端生成一系列回显远程过程调用（RPC）；每个 RPC 会将一个给定大小的数据块发送到服务器，然后服务器将该数据块返回给客户端。客户端会伪随机地选择 RPC 大小，以匹配图 1 中的其中一种工作负载，并将泊松到达过程配置为产生特定的网络负载。每个 RPC 的服务器是随机选取的。
图 8 绘制了 Homa 和其他几种 RAMCloud 传输协议在 80% 网络负载下处理工作负载 W3 - W5 时的性能（工作负载 W1 和 W2 未显示，因为 RAMCloud 的软件开销过高，无法在 80% 网络利用率的情况下处理这些工作负载产生的大量小消息）。我们评估 Homa 的主要指标如图 8 所示，是第 99 百分位的尾延迟，其中延迟是完成一个回显远程过程调用（RPC）实际所需时间除以在空载网络上该大小 RPC 的最佳可能时间的比率。延迟为 1 是理想情况。每个图的 x 轴进行了缩放以匹配消息大小的累积分布函数（CDF）：该轴在消息总数上是线性的，刻度对应于该工作负载中所有消息的 10%。这导致每个工作负载有不同的 x 轴刻度，这使得更容易查看最常见消息大小的结果。
在各种不同的远程过程调用（RPC）大小和工作负载情况下，Homa 的第 99 百分位尾延迟在 2 到 3.5 的范围内。例如，在空载网络中，一个 100 字节的回显 RPC 需要 4.7 微秒；在 80%的网络负载下，这三种负载中第 99 百分位的延迟均约为 14 微秒。
