---
marp: true
paginate: true
theme: default
footer: It's Time to Replace TCP in the Datacenter
math: mathjax
transition: push
style: |-
  .slide {
    font-family: '汉仪旗黑 50S' !important;
  }
  section.homa h1 {
    color: #102C57;
    opacity: 0.7;
  }
---

<!-- _class: homa -->

# <!--fit--> _Homa_

_It's Time to Replace TCP in the Datacenter_

_[fanyang@smartx.com](fanyang@smartx.com)_

---

# 背景

- 数据中心中拥有数以百万计的核心；数千台机器在微秒级别交互
- TCP 表现不佳，在许多层面上引入了开销，从而限制了应用程序级的性能。
  - TCP 在混合工作负载下遭受短消息的高尾部延迟。
- TCP 是“数据中心税”的主要贡献者
  - 这是一组低级开销，消耗了数据中心所有处理器周期的很大一部分
- TCP 的每一个重要元素，从面向流到期望按顺序发送数据包，对数据中心来说都是错误的

---

# 需求

- 可靠传输
- 低延迟
  - 现代网络硬件
  - 低长尾延迟
- 高吞吐
  - 在单个消息或流中传递大量数据
  - 能够快速发送大量小消息

---

# 需求

为了满足上述需求，还需要处理以下问题：

- 拥塞控制
- 跨服务器内核的高效负载平衡
- 网卡卸载

---

# TCP 关键设计

- 面向流
- 面向连接
- 共享带宽 (“公平” 调度)
- 发送端驱动的拥塞控制
- 按序数据包交付

---

# TCP：面向流

- TCP 的数据模型是一个字节流
  - 应用程序在序列化消息时必须标记消息边界
- TCP 应用程序必须使用两种较差的负载均衡形式之一，即每个流由单个线程拥有
  1. 第一种方法，是在线程之间静态划分一组流
  2. 专门安排一个线程读取来自所有流的所有传入消息，然后将消息分派给其他线程进行服务
- 流的根本问题是接收数据的单位（字节范围）与可分派的工作单位（消息）不对应
- 在单个流中发送的消息必须按顺序接收；这意味着短消息可能会在同一流中的长消息之后延迟
- 流提供的可靠性保证并不适合应用程序，应用程序需要往返保证
  - 客户端必须实现自己的端到端超时机制

---

# TCP：面向连接

- TCP 要求应用程序与之通信的每个对等点都有长期存在的连接状态
  - 例如，Linux 内核为每个 TCP 套接字保留大约 2000 字节的状态，不包括数据包缓冲区
  - 应用程序级别需要额外的状态
- 由于 NIC 芯片上的资源有限，在将传输卸载到 NIC 时，连接状态的开销也很成问题
- 连接的另一个问题是，在传输任何数据之前，它们需要一个设置阶段
  - Serverless 环境下，应用程序的生命周期非常短

---

# TCP：带宽共享

- 在 TCP（传输控制协议）中，当一台主机的链路过载（无论是传入流量还是传出流量）时，TCP 会尝试在所有活动连接之间平均分配可用带宽。这种方法也被称为 “公平调度”。
- 当接收到若干条大消息时，带宽共享会导致所有这些消息都缓慢完成处理
- SRPT（最短剩余处理时间）这类运行至完成的方法能提供更优的整体响应时间，因为它们每次会将所有可用资源都投入到单个任务上
  - 使用 TCP 来实现运行至完成是很困难的，因为 TCP 并不知晓消息边界的相关信息
- 尽管名为“公平调度”，但 TCP 的这种做法对短消息极为不利

---

# TCP：拥塞控制

- TCP 的拥塞控制由发送方驱动，当发送方检测到拥塞时，会主动降低其数据包的传输速率
  - 发送方并不直接了解拥塞情况
- 束缚：
  - 只有在缓冲区被占用时才能检测到拥塞
  - TCP 没有利用现代网络交换机中的优先级队列；所有数据包都被同等对待
- 这些限制导致了一种“两难困境”，即很难同时优化延迟和吞吐量
  - 要确保短消息的低延迟，唯一的办法就是让网络中的队列长度接近于零：尽管有流量可以使用链路，但链路却处于空闲状态；这会降低长消息的吞吐量
  - 唯一的办法就是允许在稳定状态下积累缓冲区，但这会给短消息造成延迟
- 发送方大约需要一个往返时间（RTT）才能察觉到流量的变化

---

# TCP：按序数据包交付

- TCP 假定数据包会按照发送方发送的相同顺序到达接收方
  - 在数据中心网络中，执行负载均衡最有效的方法是进行 packet spraying：每个数据包都通过交换架构独立路由，以平衡链路上的负载
  - TCP 网络必须使用流一致路由，即来自给定连接的所有数据包都通过网络架构遵循相同的路径
  - 这导致了即使在整体网络负载较低时，网络核心中也会存在过载链路
- 按序数据包交付也会在软件中引发热点问题
- 数据中心网络中的不对称性可能会导致严重的数据包重新排序，超出 TCP 的容忍范围

---

# Homa 基础

- 基于消息
  - 向传输层提供了可调度的单元。这使得负载均衡更加高效
  - 多个线程可以安全地从单个套接字读取数据
  - 具有明确的消息边界还能够在传输中实现诸如最短剩余处理时间（SRPT）这样的运行至完成调度
  - 消息有一个劣势：对单个大型消息的实现进行流水线操作比较困难
- 无连接
- SPRT
  - 利用了现代交换机所提供的优先级队列。这使得优先级较高（较短）的消息能够绕过为优先级较低（较长）的消息所排队的数据包
  - 防止饥饿：每台主机的一小部分带宽（通常为 5%至 10%）会专门分配给最旧的消息，而非最短的消息
- 接收方驱动的拥塞控制
  - 拥塞主要发生在接收方的下行链路
  -
