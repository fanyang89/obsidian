## 嵌套集群

```
[root@mazg-smtxos630-vhost-2-instX1 16:53:21 ~]$ curl -s http://127.0.0.1:10300/api/v1/watchdog/log_warn | grep "kill zk"
W2025-07-31 15:19:01.999114  [http_server.h:113] [KILL EVENT] filesystem readonly continues 15 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:01.999774  [http_server.h:190] kill zk, pid: 3055, ret: 0
W2025-07-31 15:19:06.999141  [http_server.h:113] [KILL EVENT] filesystem readonly continues 20 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:06.999249  [http_server.h:190] kill zk, pid: 3055, ret: 0
W2025-07-31 15:19:11.999120  [http_server.h:113] [KILL EVENT] filesystem readonly continues 25 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:11.999234  [http_server.h:190] kill zk, pid: 3055, ret: 0

[root@mazg-smtxos630-vhost-2-instX2 16:53:22 ~]$ curl -s http://127.0.0.1:10300/api/v1/watchdog/log_warn | grep "kill zk"
W2025-07-31 15:19:03.286051  [http_server.h:113] [KILL EVENT] filesystem readonly continues 15 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:03.287245  [http_server.h:190] kill zk, pid: 3026, ret: 0
W2025-07-31 15:19:08.286031  [http_server.h:113] [KILL EVENT] filesystem readonly continues 20 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:08.286167  [http_server.h:190] kill zk, pid: 3026, ret: 0
W2025-07-31 15:19:13.286007  [http_server.h:113] [KILL EVENT] filesystem readonly continues 25 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:13.286086  [http_server.h:190] kill zk, pid: 3026, ret: 0

[root@mazg-smtxos630-vhost-2-instX3 16:53:23 ~]$ curl -s http://127.0.0.1:10300/api/v1/watchdog/log_warn | grep "kill zk"
W2025-07-31 15:19:04.639520  [http_server.h:113] [KILL EVENT] filesystem readonly continues 15 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:04.640267  [http_server.h:190] kill zk, pid: 2946, ret: 0
W2025-07-31 15:19:09.639503  [http_server.h:113] [KILL EVENT] filesystem readonly continues 20 seconds,will kill zk & meta & mongod & vipservice(if not found kill taskd) once
W2025-07-31 15:19:09.639618  [http_server.h:190] kill zk, pid: 2946, ret: 0
```

## 物理主机

```
W0731 15:18:47.166129 38708(db-cluster-io) db_cluster.cc:1383] [SLOW ZK COMMIT] takes 3261 ms. retried 454 times
```

```
E0731 15:18:44.264618 17685(zoo-io) main.cc:96] [ZOO] handle_socket_error_msg:2661 2025-07-31 15:18:44,264 17642(0x7efcf77fe700) ERR handle_socket_error_msg:2661] Socket [10.10.131.204:2181] zk retc
ode=-4, errno=104(Connection reset by peer): failed while receiving a server response
I0731 15:18:44.264963 17685(zoo-io) main.cc:104] [ZOO] check_events:2643 2025-07-31 15:18:44,264 17642(0x7efcf77fe700) INF check_events:2643] initiated connection to server [10.10.131.205:2181]
W0731 15:18:44.265210 17687(quorum) zookeeper.cc:239] zookeeper session event: CONNECTED_STATE --> CONNECTING_STATE
W0731 15:18:44.265236 17687(quorum) zookeeper.cc:208] Start the session timeout timer: 2848ms, client_id: 0x800198ee30d0012
I0731 15:18:44.265260 17687(quorum) quorum_cluster.cc:394] QuorumCluster state change: Running --> Running_Connecting
W0731 15:18:44.265352 38708(db-cluster-io) db_cluster.cc:1352] failed to create zk journal /zbs/meta/__mj_j/0000000002c1c1a6/0000000002c1c2d5 for the first time:
Traceback:
[EZKConnectError]:  path: /zbs/meta/__mj_j/0000000002c1c1a6/0000000002c1c2d5
```

```
2025-07-31T15:18:44,265 [myid:] - INFO  [NIOWorkerThread-2:Learner@112] - Revalidating client: 0x800198ee30d0012
2025-07-31T15:18:44,266 [myid:] - WARN  [NIOWorkerThread-3:ZooKeeperServer@1078] - Connection request from old client /10.10.131.204:37332; will be dropped if server is in r-o mode
2025-07-31T15:18:44,266 [myid:] - WARN  [NIOWorkerThread-1:ZooKeeperServer@1078] - Connection request from old client /10.10.131.206:49948; will be dropped if server is in r-o mode
2025-07-31T15:18:44,266 [myid:] - INFO  [NIOWorkerThread-1:Learner@112] - Revalidating client: 0x60019680e8e0189
2025-07-31T15:18:44,266 [myid:] - INFO  [NIOWorkerThread-2:Learner@112] - Revalidating client: 0x7001931d02e0039
2025-07-31T15:18:44,268 [myid:] - WARN  [NIOWorkerThread-2:NIOServerCnxn@370] - Exception causing close of session 0x7001931d02e0039: Broken pipe (Write failed)
2025-07-31T15:18:44,268 [myid:] - WARN  [NIOWorkerThread-1:NIOServerCnxn@370] - Exception causing close of session 0x60019680e8e0189: Broken pipe (Write failed)
```

```
[root@node131-205 17:02:52 2025-07-31]$ rpm -qa | grep zoo
zookeeper-lib-3.9.9-27.xtal.el7.x86_64
zookeeper-3.9.9-27.xtal.el7.x86_64
[root@node131-205 17:02:56 2025-07-31]$ rpm -qa | grep jdk
copy-jdk-configs-3.3-11.el7_9.noarch
java-1.8.0-openjdk-headless-1.8.0.402.b06-1.el7_9.x86_64
```

```
[root@node131-202 17:18:51 ~]$ journalctl -u zookeeper | grep code | grep 'Jul 31'
Jul 31 15:16:59 node131-202 systemd[1]: zookeeper.service: main process exited, code=exited, status=143/n/a

[root@node131-205 17:19:06 ~]$ journalctl -u zookeeper | grep code | grep 'Jul 31'
Jul 31 15:17:39 node131-205 systemd[1]: zookeeper.service: main process exited, code=exited, status=143/n/a

[root@node131-203 17:19:03 ~]$ journalctl -u zookeeper | grep code | grep 'Jul 31'
Jul 31 15:16:07 node131-203 systemd[1]: zookeeper.service: main process exited, code=exited, status=143/n/a

[root@node131-206 17:19:09 ~]$ journalctl -u zookeeper | grep code | grep 'Jul 31'
Jul 31 15:18:12 node131-206 systemd[1]: zookeeper.service: main process exited, code=exited, status=143/n/a

[root@node131-204 17:19:04 2025-07-31]$ journalctl -u zookeeper | grep code | grep 'Jul 31'
Jul 31 15:18:44 node131-204 systemd[1]: zookeeper.service: main process exited, code=exited, status=143/n/a
```

## zg q1

> 205 成为 zk leader 之后的一段时间里有很多异常。之后 204 再次成为 leader。这段时间应该是有问题的。

```
2025-07-31T15:18:49,095 [myid:] - INFO [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):QuorumPeer@751] - Peer state changed: leading - broadcast
```

### 205 zookeeper

```
2025-07-31T15:18:44,309 [myid:] - INFO  [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):QuorumPeer@1277] - LOOKING
2025-07-31T15:18:45,757 [myid:] - INFO  [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):QuorumPeer@1277] - LOOKING
2025-07-31T15:18:47,647 [myid:] - INFO  [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):QuorumPeer@1365] - LEADING
2025-07-31T15:18:49,084 [myid:] - INFO  [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):Leader@1353] - Have quorum of supporters, sids: [[8, 9, 6]]; starting up and setting last processed zxid: 0xc00000000
2025-07-31T15:18:50,059 [myid:] - WARN  [RecvWorker:6:QuorumCnxManager$RecvWorker@1245] - Connection broken for id 6, my id = 9, error = java.net.SocketException: Connection reset
2025-07-31T15:18:50,096 [myid:] - INFO  [QuorumPeer[myid=9](plain=10.10.131.205:2181)(secure=disabled):Leader@680] - Shutdown called
java.lang.Exception: shutdown Leader! reason: Not sufficient followers synced, only synced with sids: [ [8, 9] ]
```

检查 myid=6

```
[root@node131-202 17:31:46 ~]$ cat /var/lib/zbs/metad/zookeeper/myid
6

2025-07-31T15:18:47,464 [myid:] - INFO  [QuorumPeer[myid=6](plain=10.10.131.202:2181)(secure=disabled):QuorumPeer@745] - Peer state changed: following
2025-07-31T15:18:48,939 [myid:] - WARN  [QuorumPeer[myid=6](plain=10.10.131.202:2181)(secure=disabled):Follower@100] - Exception when following the leader, java.net.SocketTimeoutException: Read timed out
2025-07-31T15:18:49,993 [myid:] - INFO  [QuorumPeer[myid=6](plain=10.10.131.202:2181)(secure=disabled):FastLeaderElection@989] - Restart FLE since the max notification interval is reached
2025-07-31T15:18:50,045 [myid:] - INFO  [/10.10.131.202:3888:QuorumCnxManager$Listener@967] - Leaving listener
```
